### Cell 1: Imports and Setup
import os
import glob
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, Add, Lambda, UpSampling2D
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

print(f"TensorFlow Version: {tf.__version__}")
print(f"GPU Available: {'Yes' if tf.config.list_physical_devices('GPU') else 'No'}")

### Cell 2: Configuration
# --- Data Configuration ---
DATA_DIR = 'data/'
TRAIN_LR_DIR = os.path.join(DATA_DIR, 'train/lr')
TRAIN_HR_DIR = os.path.join(DATA_DIR, 'train/hr')
VAL_LR_DIR = os.path.join(DATA_DIR, 'val/lr')
VAL_HR_DIR = os.path.join(DATA_DIR, 'val/hr')
TEST_LR_DIR = os.path.join(DATA_DIR, 'test/lr')
TEST_HR_DIR = os.path.join(DATA_DIR, 'test/hr')

# --- Model & Training Configuration ---
LR_SIZE = (64, 64)
HR_SIZE = (256, 256)
UPSCALE_FACTOR = 4
CHANNELS = 3
RESIDUAL_BLOCKS = 8
FILTERS = 64

# --- Training Hyperparameters ---
LEARNING_RATE = 1e-4
BATCH_SIZE = 16 # Adjust based on your GPU memory
EPOCHS = 100 # Increase for better results

### Cell 3: PSNR Custom Metric
def psnr(y_true, y_pred):
    """
    Peak Signal-to-Noise Ratio metric.
    Assumes input images are in the range [0, 1].
    """
    return tf.image.psnr(y_true, y_pred, max_val=1.0)

### Cell 4: EDSR-like Model Definition
def residual_block(x, filters):
    """A single residual block for the EDSR model."""
    # Main path
    res = Conv2D(filters, (3, 3), padding='same', activation='relu')(x)
    res = Conv2D(filters, (3, 3), padding='same')(res)
    # Add skip connection
    x = Add()([x, res])
    return x

def upsampling_block(x, filters):
    """Upsampling block using sub-pixel convolution (depth_to_space)."""
    # 2x upscale
    x = Conv2D(filters * 4, (3, 3), padding='same')(x)
    x = tf.nn.depth_to_space(x, 2)
    return x

def build_edsr_like_model(lr_shape, upscale_factor, channels, residual_blocks, filters):
    """Builds the EDSR-like super-resolution model."""
    inputs = Input(shape=(lr_shape[0], lr_shape[1], channels))
    
    # Pre-processing (normalize to [0, 1]) is done in the data pipeline
    # The model expects normalized inputs
    x = inputs

    # Initial feature extraction layer
    x = Conv2D(filters, (3, 3), padding='same')(x)
    conv1_out = x

    # Stack of residual blocks
    for _ in range(residual_blocks):
        x = residual_block(x, filters)

    # Post-residual block convolution
    x = Conv2D(filters, (3, 3), padding='same')(x)
    x = Add()([conv1_out, x])

    # Upsampling blocks (two 2x blocks for a total 4x upscale)
    x = upsampling_block(x, filters) # 2x upscale
    x = upsampling_block(x, filters) # 4x upscale
    
    # Final output layer
    outputs = Conv2D(channels, (3, 3), padding='same', activation='sigmoid')(x)

    model = Model(inputs, outputs, name="EDSR_like_SuperResolution")
    return model

# Build and compile the model
model = build_edsr_like_model(
    lr_shape=LR_SIZE,
    upscale_factor=UPSCALE_FACTOR,
    channels=CHANNELS,
    residual_blocks=RESIDUAL_BLOCKS,
    filters=FILTERS
)

model.compile(
    optimizer=Adam(learning_rate=LEARNING_RATE),
    loss='mae',  # Mean Absolute Error
    metrics=[psnr]
)

model.summary()


### Cell 5: Data Loading and Preprocessing Pipeline
def load_and_preprocess(lr_path, hr_path):
    """Loads and preprocesses a single LR/HR image pair."""
    lr_img = tf.io.read_file(lr_path)
    lr_img = tf.image.decode_png(lr_img, channels=3)
    lr_img = tf.image.convert_image_dtype(lr_img, tf.float32)

    hr_img = tf.io.read_file(hr_path)
    hr_img = tf.image.decode_png(hr_img, channels=3)
    hr_img = tf.image.convert_image_dtype(hr_img, tf.float32)
    
    return lr_img, hr_img

def create_dataset(lr_dir, hr_dir, batch_size):
    """Creates a tf.data.Dataset for training, validation, or testing."""
    lr_paths = sorted(glob.glob(os.path.join(lr_dir, "*.png")))
    hr_paths = sorted(glob.glob(os.path.join(hr_dir, "*.png")))
    
    if not lr_paths or not hr_paths:
        raise ValueError(f"No images found in directories: {lr_dir}, {hr_dir}")

    dataset = tf.data.Dataset.from_tensor_slices((lr_paths, hr_paths))
    dataset = dataset.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    
    # For training, shuffle the data
    if 'train' in lr_dir:
        dataset = dataset.shuffle(buffer_size=len(lr_paths))
        
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
    
    return dataset

# Create datasets
train_ds = create_dataset(TRAIN_LR_DIR, TRAIN_HR_DIR, BATCH_SIZE)
val_ds = create_dataset(VAL_LR_DIR, VAL_HR_DIR, BATCH_SIZE)
test_ds = create_dataset(TEST_LR_DIR, TEST_HR_DIR, BATCH_SIZE)

print(f"Training dataset:   {train_ds}")
print(f"Validation dataset: {val_ds}")
print(f"Test dataset:       {test_ds}")


### Cell 6: Train the Model
history = model.fit(
    train_ds,
    epochs=EPOCHS,
    validation_data=val_ds,
    verbose=1
)

# Optional: Save the model
# create_dir('models')
# model.save('models/edsr_like_model.h5')

### Cell 7: Plot Training History
def plot_history(history):
    """Plots the training and validation loss and PSNR."""
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))

    # Plot Loss
    axes[0].plot(history.history['loss'], label='Training Loss')
    axes[0].plot(history.history['val_loss'], label='Validation Loss')
    axes[0].set_title('Training vs. Validation Loss')
    axes[0].set_xlabel('Epochs')
    axes[0].set_ylabel('Loss (MAE)')
    axes[0].legend()
    axes[0].grid(True)

    # Plot PSNR
    axes[1].plot(history.history['psnr'], label='Training PSNR')
    axes[1].plot(history.history['val_psnr'], label='Validation PSNR')
    axes[1].set_title('Training vs. Validation PSNR')
    axes[1].set_xlabel('Epochs')
    axes[1].set_ylabel('PSNR (dB)')
    axes[1].legend()
    axes[1].grid(True)

    plt.tight_layout()
    plt.show()

plot_history(history)


### Cell 8: Quantitative Evaluation on Test Set
print("Evaluating model on the test set...")
results = model.evaluate(test_ds, verbose=1)

print("\n--- Test Set Evaluation ---")
print(f"Test Loss (MAE): {results[0]:.4f}")
print(f"Test PSNR (dB):  {results[1]:.4f}")
print("---------------------------")


### Cell 9: Qualitative Evaluation (Visual Comparison)
def plot_test_results(model, dataset, num_images_to_show=5):
    """
    Displays a side-by-side comparison of Bicubic, Model SR, and Ground Truth.
    """
    for lr_batch, hr_batch in dataset.take(1):
        # Generate predictions
        sr_batch = model.predict(lr_batch)

        for i in range(min(num_images_to_show, len(lr_batch))):
            lr_img = lr_batch[i].numpy()
            sr_img = sr_batch[i] # Already a numpy array after predict
            hr_img = hr_batch[i].numpy()

            # Bicubic upscale for comparison
            bicubic_img = tf.image.resize(lr_img, HR_SIZE, method='bicubic').numpy()

            # Clip values to be in the valid [0, 1] range for display
            lr_img = np.clip(lr_img, 0.0, 1.0)
            bicubic_img = np.clip(bicubic_img, 0.0, 1.0)
            sr_img = np.clip(sr_img, 0.0, 1.0)
            hr_img = np.clip(hr_img, 0.0, 1.0)

            # Calculate PSNR for this specific image
            psnr_bicubic = tf.image.psnr(tf.convert_to_tensor(bicubic_img), tf.convert_to_tensor(hr_img), max_val=1.0).numpy()
            psnr_model = tf.image.psnr(tf.convert_to_tensor(sr_img), tf.convert_to_tensor(hr_img), max_val=1.0).numpy()

            # Plotting
            fig, axes = plt.subplots(1, 3, figsize=(20, 7))
            
            axes[0].imshow(bicubic_img)
            axes[0].set_title(f'Bicubic Upscale\nPSNR: {psnr_bicubic:.2f} dB')
            axes[0].axis('off')

            axes[1].imshow(sr_img)
            axes[1].set_title(f'Model Super-Resolution\nPSNR: {psnr_model:.2f} dB')
            axes[1].axis('off')

            axes[2].imshow(hr_img)
            axes[2].set_title('Ground Truth (HR)')
            axes[2].axis('off')

            plt.show()

# Run the visual comparison
plot_test_results(model, test_ds, num_images_to_show=5)